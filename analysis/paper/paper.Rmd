---
title: "An evaluation framework for trajectory inference methods"
author:
  - Robrecht Cannoodt* ¹ ² ³
  - Wouter Saelens* ¹ ²
  - Helena Todorov¹ ²
  - Yvan Saeys¹ ²
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::html_document2:
    fig_caption: yes
    reference_docx: templates/template.docx
bibliography: references.bib
csl: nature-biotechnology.csl
abstract: |
  Using single-cell transcriptomics data, it is now possible to computationally order cells along trajectories, allowing the unbiased transcriptome-wide study of cellular dynamic processes. Dozens of trajectory inference methods have been developed, early methods mostly focussing on linear trajectories, while recently methods also model more complex branching trajectories. However, the performance of these methods have not yet been comprehensively evaluated. Here, we compare a total of 22 trajectory inference methods, on both realistic synthetic datasets and a large set is real datasets. We employ a novel parameter optimisation procedure, and compare methods using several metrics, including accuracy of the inferred ordering, correctness of the network wiring, code quality and user friendliness. We conclude with practical guidelines for method users, and also believe our evaluation framework can be used to spearhead the development for new methods. Our evaluation pipeline is fully reproducible, can be easily extended and is available at www.github.com/dynverse.
keywords: |
  trajectory inference; pseudotemporal ordering; single-cell transcriptomics
highlights: |
  These are the highlights. 
---
\* Equal contribution  
¹ Data mining and modelling for biomedicine, VIB Center for Inflammation Research, Ghent, Belgium  
² Department of ???, Ghent University, Ghent, Belgium  
³ Center for Medical Genetics, Ghent University  

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  comment = "#>",
  fig.path = "analysis/figures/"
)

library(dynalysis)
library(tidyverse)
library(cowplot)

# refering to figures & supplementary figures
refs <- tibble(ref_id = character(), name = character(), ref_type = character())
ref <- function(ref_type, ref_id, suffix="", anchor=FALSE) {
  if(nrow(refs %>% filter(ref_id == !!ref_id)) == 0) {
    refs <<- refs %>% bind_rows(tibble(
      name = create_names[[ref_type]](sum(refs$ref_type == ref_type) + 1),
      ref_type = ref_type,
      ref_id = ref_id
    ))
  }
  ref <- refs %>% filter(ref_id == !!ref_id) %>% 
    pull(name) %>% 
    {pritt("[**{.}{suffix}**](#{ref_type}_{ref_id})")}
  
  if (anchor) ref <- pritt("{ref}<a name='{ref_type}_{ref_id}'></a>")
  ref
}
create_names <- list(
  sfig = function(i) {pritt("Supplementary Figure {i}")},
  fig = function(i) {pritt("Figure {i}")}
)
```
# Introduction


Single-cell[a] -omics technologies now make it possible to more accurately model biological systems than ever before. One area where single-cell data can be particularly useful is in the study of cellular dynamic processes, such as the cell cycle, cell differentiation and cell activation. When cells are sampled from a population in which cells are at different unknown points in the dynamic process, trajectory inference methods can be used to computationally order these cells along their dynamic process [@cannoodt_computational_2016]. Because they offer an unbiased and transcriptome-wide understanding of the dynamic process, trajectories then allow the identification new (primed) subsets of cells, delineation the exact wiring of a differentiation tree and inference of regulatory interaction responsible for a bifurcation refs.


```{r, fig.width = 15, fig.height = 10}
n_methods_over_time <- readRDS(figure_file("n_methods_over_time.rds", experiment_id="method_characteristics"))
trajectory_components_over_time <- readRDS(figure_file("trajectory_components_over_time.rds", experiment_id="method_characteristics"))


cowplot::plot_grid(plotlist=list(n_methods_over_time, trajectory_components_over_time), nrow=2, rel_heights = c(0.7, 0.3), labels="auto")
```


`r ref("sfig", "methods_over_time", anchor=TRUE)` New TI methods over time. **a** Number of methods published or in preprint. **b** Number of methods which can handle a particular type of trajectory.


Dozens[b] of trajectory inference methods have been developed over the last years, and more are being published almost every month (`r ref("sfig", "methods_over_time", "a")`). Initially most trajectory inference was focused on linear trajectories, with one start and one end point. However, the prospect of branching trajectories was already described early [@trapnell_dynamics_2014], and about half of the current methods can handle one or more bifurcations in the trajectory (`r ref("sfig", "methods_over_time", "b")`). Some methods can already handle more complex, cyclical and branching behaviour, and it is expected that in the future methods will be able to model even more complex behavior, such as multiple dynamic processes happening at parallel in a single-cell or the integration of datasets from different patients [@tanay_scaling_2017; @cannoodt_computational_2016].


Although[c] trajectory inference methods use a variety of algorithms and subcomponents to reach a final ordering, most consist of the following three steps: (i) preprocessing (filtering of genes and/or cells), (ii) conversion to a simplified representation using dimensionality reduction or clustering and (iii) ordering the cells along the simplified representation. These components are frequently interchangeable. Depending on the way the cells are ordered, some prior information about the dynamic process can also be required, or optional. 


Given[d] this plethora of available trajectory inference methods, it is important that methods are compared, so that users can use the most optimal method available for their problem. Moreover, new methods need to be rigorously tested, so that development can focus on improving the current state-of-the-art. In this study, we therefore for the first time developed a comprehensive evaluation framework for trajectory inference methods. We test both on synthetic data, for which the gold standard is known, and real data, for which in some cases the gold standard can be extracted from expert knowledge. We include a rigorous parameter optimisation, making sure that parameters are optimized while avoiding overfitting on characteristics of specific datasets. To make our framework reusable and extendable, we make use of continuous analysis [@beaulieu-jones_reproducibility_2017], which allows the developers of new methods to easily test their methods and compare them against the state-of-the-art.
# Results
## Evaluation workflow
### Method characterization
```{r}
# Load method characteristics
method_df <- readRDS(derived_file("method_df.rds", experiment_id="method_characteristics"))
```


We gathered a list of `r sum(method_df$is_ti == "Yup", na.rm=TRUE)` TI methods from literature, and selected a subset of `r sum(!is.na(method_df$qc_score))` for evaluation, primarily based on their free availability and the presence of a programming interface. We characterized all methods in four different ways: underlying algorithm(s), implementation quality, prior information and possible trajectory structures (`r ref("fig", "method_characteristics")`). The underlying algorithms can be divided into several subcomponents, and these components are frequently shared between different algorithms. Some components, such as a minimal spanning tree or principal curves for cellular ordering, or PCA or diffusion map for dimensionality reduction are shared by more than 5 methods sFIG?. While not directly related to the quality of the inferred trajectory, the quality of the implementation is an important first evaluation metric, because good unit testing makes sure the implementation is correct, good documentation makes it easier for potential users to apply the method on their data, and overall good code quality makes it possible for other developers to adapt the method and extend it further. We therefore looked at the implementation of each method, and assessed their implementation quality using a transparent scoring scheme sNOTE. After initial scoring we contacted all the authors, to allow them to improve their method before publishing. While most methods lack at several metrics (`r ref("fig", "method_characteristics", "a")`), recent methods tend to have higher code quality sFIG. However, some implementation details are lacking for the majority of the methods and should receive extra attention from developers: code availability, documentation and unit testing (`r ref("fig", "method_characteristics", "a")`).


```{r, fig.width = 12, fig.height = 9}
method_characteristics <- readRDS(figure_file("method_characteristics.rds", experiment_id="method_characteristics"))


print(method_characteristics)
```


`r ref("fig", "method_characteristics", anchor=TRUE)` FIrst characterization of each method.


### Data sources
![evaluation_overview](../../analysis/figures/evaluation_overview.png)
`r ref("fig", "evaluation_overview", anchor=TRUE)` Overview of the evaluation


We use three types of datasets for our evaluation
### Score metrics and parameter optimisation


## Overall method comparison
- Some methods can handle different trajectories which are not directly described in the main paper: eg. circular trajectories (for a lot of principal curves algorithms using `periodic.lowess`), trees (for a lot of bifurcation methods)


## Evaluation on synthetic data
Initial evaluation..
Robustness..
Gegenereerde synthetische data. Parameter tuning voor echte data + initiële evaluatie (tot wat is de methode in staat) + robustness etc testing


## Evaluation on real data
Biological relevance..
Echte data. Evaluatie (biologische relevantie van de methode)


# Discussion


# Conclusion


# Online Methods


# Acknowledgements


# Colophon


This report was generated on `r Sys.time()` using the following computational environment and dependencies: 


```{r colophon, cache = FALSE}
# which R packages and versions?
devtools::session_info()
```


The current Git commit details are:


```{r}
# what commit is this file at? You may need to change the path value
# if your Rmd is not in analysis/paper/
git2r::repository(".")
```


# References 


[a]General info about single-cell & trajectories
[b]History of TI, different methods
[c]Common framework of TI, different components, naturally progressing towards the need for an evaluation
[d]Context and general overview of our evaluation