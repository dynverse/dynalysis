% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/suite_benchmark.R
\name{generate_benchmark_design}
\alias{generate_benchmark_design}
\title{Generate a benchmarking design}
\usage{
generate_benchmark_design(datasets, methods, parameters = NULL,
  give_priors = NULL, num_repeats = 1)
}
\arguments{
\item{datasets}{The datasets to be used in the evaluation.
Must be a named list consisting of dataset ids (character),
dynwrap::data_wrapper's, or functions that generate dynwrap::data_wrapper's.}

\item{methods}{The methods to be evaluated.
Must be a named list consisting of method_ids (character) or dynwrap::ti_wrapper's.}

\item{parameters}{A named list containing data frames of the parameters to evaluate.
The names of the list must be present in method_ids.
The data frames must be of format \code{data_frame(paramset_id = "set1", param1 = "a", param2 = 2.0)}.}

\item{give_priors}{All the priors a method is allowed to receive. Must be a subset of: \code{"start_milestones"},
\code{"start_id"}, \code{"end_milestones"}, \code{"end_id"}, \code{"groups_id"} and \code{"groups_network"}}

\item{num_repeats}{The number of times to repeat the evaluation.}
}
\description{
Generate a benchmarking design
}
\examples{
\donttest{
library(tibble)
generate_benchmark_design(
  datasets = list(
    "toy/bifurcating_1",
    dyntoy::generate_dataset(unique_id = "test"),
    test2 = function() dyntoy::generate_dataset(unique_id = "test")
  ),
  methods = list("scorpius", dynmethods::ti_scorpius(), "tscan"),
  parameters = list(
    scorpius = tibble(paramset_id = "default"),
    tscan = tibble(
      paramset_id = paste0("test", 1:3),
      clusternum_lower = 4:6,
      clusternum_upper = 18:20
    )
  ),
  give_priors = NULL,
  num_repeats = 2
)
}
}
